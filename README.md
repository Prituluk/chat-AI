# ğŸš€ Chat-AI  

> AplicaciÃ³n que permite probar modelos de IA **localmente** usando **Ollama, Gemma 3 y DeepSeek-R1**.  

---

## ğŸ“Œ CaracterÃ­sticas  
âœ… Funciona localmente sin depender de la nube.  
âœ… Soporta modelos ligeros como **Gemma 3 (4B)**.  
âœ… FÃ¡cil de instalar y usar.  

---

## ğŸ› ï¸ InstalaciÃ³n y primeros pasos  

### 1ï¸âƒ£ **Clona este repositorio**  
```sh
git clone https://github.com/tu-usuario/chat-ai.git
cd chat-ai
```
### 2ï¸âƒ£ **Instala Ollama**  
ğŸ”—DescÃ¡rgalo desde su web oficial: [Ollama](https://ollama.com/download)

### 3ï¸âƒ£ **Descarga un modelo de IA**  
ğŸ”—Busca y descarga un modelo compatible desde: [Modelos AI](https://ollama.com/search)
En este caso, instalamos Gemma 3 (4B):
```sh
ollama pull gemma3:4b
```
âš ï¸ **IMPORTANTE**: Instala un modelo acorde a tu hardware para evitar sobrecargas o bloqueos en tu PC.

### 4ï¸âƒ£ **Inicia Ollama**  
Ejecuta el siguiente comando para levantar el servidor de IA:
```sh
ollama serve
```
### 5ï¸âƒ£ **Ejecuta la app**  
Puedes usar Live Server (VS Code) o cualquier servidor local para abrir el proyecto.

### 6ï¸âƒ£ **Consulta la IA**  
Haz preguntas y experimenta con la IA en la interfaz de la app.

### 7ï¸âƒ£ **Finaliza la ejecuciÃ³n**  
Cuando termines, detÃ©n Ollama con:
```sh
  Ctrl + C
```


## âš¡ Recomendaciones
âœ” Cierra otras aplicaciones para liberar recursos.

âœ” Monitorea el uso de RAM y CPU con el Administrador de tareas.

âœ” Usa modelos pequeÃ±os si tu PC tiene poca RAM (Ej: 4B en lugar de 7B o mÃ¡s). 


## ğŸ“œ Licencias de los Modelos
Cada modelo de IA tiene su propia licencia de uso, lo que significa que algunos pueden tener restricciones para aplicaciones comerciales o modificaciones.

ğŸ”¹ Antes de usar un modelo, revisa su licencia en la web oficial de Ollama:
ğŸ”— [Lista de modelos y sus licencias](https://ollama.com/search)

Ejemplo:

âºï¸ Gemma 3 â†’ Licencia de Google, con restricciones de uso comercial.

âºï¸ DeepSeek-R1 â†’ Puede tener tÃ©rminos distintos segÃºn su proveedor.


## ğŸ¤ Contribuciones
Si tienes mejoras o ideas, Â¡haz un fork y envÃ­a un pull request! ğŸš€